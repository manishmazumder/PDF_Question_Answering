{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishmacbook/miniforge3/envs/pdf_qa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LangChain components to use\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
    "# you will also initialize the DB connection:\n",
    "import cassio\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ASTRA_DB_APP_TOKEN = os.getenv('ASTRA_DB_APP_TOKEN')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ASTRA_DB_ID = os.getenv('ASTRA_DB_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of pdf files\n",
    "pdfreader = PdfReader('data/prml_bishop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the database\n",
    "cassio.init(token=ASTRA_DB_APP_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishmacbook/miniforge3/envs/pdf_qa/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/manishmacbook/miniforge3/envs/pdf_qa/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# cearting LLM object\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# creating openai embedding object\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain vector store\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 933, which is longer than the specified 800\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# We need to split the text using Character Text Split such that it should not increse token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validation set, 11, 32\\nVapnik-Chervonenkis dimension, 344\\nvariance, 20, 24, 149\\nvariational inference, 315, 462, 635\\nfor Gaussian mixture, 474\\nfor hidden Markov model, 625\\nlocal, 493\\nVC dimension, seeVapnik-Chervonenkis dimen-\\nsion\\nvector quantization, 429vertex, seenode\\nvisualization, 3\\nViterbi algorithm, 415, 629\\nvon Mises distribution, 108, 693\\nwavelets, 139\\nweak learner, 657weight decay, 10, 144, 257\\nweight parameter, 227\\nweight sharing, 268\\nsoft, 269\\nweight vector, 181\\nweight-space symmetry, 231, 281\\nweighted least squares, 668\\nwell-determined parameters, 170whitening, 299, 568\\nWishart distribution, 102, 693\\nwithin-class covariance, 189Woodbury identity, 696\\nwrapped distribution, 110\\nYellowstone National Park, 110, 681'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 100 headlines.\n"
     ]
    }
   ],
   "source": [
    "# inserting top 100 headlines\n",
    "astra_vector_store.add_texts(texts[:100])\n",
    "\n",
    "print(\"Inserted %i headlines.\" % len(texts[:100]))\n",
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"explain in 200 words what is k means clustering\"\n",
      "ANSWER: \"K means clustering is a popular unsupervised learning algorithm used in pattern recognition and machine learning. It is used to identify groups or clusters within a dataset based on their similarities. The goal of K means clustering is to find a predetermined number of clusters (represented by the letter \"K\") that can best represent the data. \n",
      "\n",
      "The algorithm works by first randomly selecting K points from the dataset as initial cluster centers. Then, each data point is assigned to the closest cluster center based on a distance measure, usually the Euclidean distance. The mean of the data points in each cluster is then calculated and becomes the new cluster center. This process is repeated until the cluster centers no longer change significantly, indicating that the algorithm has converged. \n",
      "\n",
      "The resulting clusters can be used for various purposes such as grouping similar data points together for further analysis or for data visualization purposes. K means clustering is commonly used in areas such as customer segmentation, image processing, and document clustering. \n",
      "\n",
      "However, it is important to note that the effectiveness of K means clustering is highly dependent on the initial selection of cluster centers and the choice of distance measure. Therefore, it is recommended to try different initializations and distance measures to find the most optimal clustering results.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.8688] \"past ten years. In particular, Bayesian methods have grown from a specialist niche t ...\"\n",
      "    [0.8688] \"past ten years. In particular, Bayesian methods have grown from a specialist niche t ...\"\n",
      "    [0.8675] \"In other pattern recognition problems, the training data consists of a set of input\n",
      " ...\"\n",
      "    [0.8675] \"In other pattern recognition problems, the training data consists of a set of input\n",
      " ...\"\n",
      "\n",
      "QUESTION: \"is k means clustering a suopervised learning algorithm?\"\n",
      "ANSWER: \"No, k means clustering is an unsupervised learning algorithm.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.9028] \"In other pattern recognition problems, the training data consists of a set of input\n",
      " ...\"\n",
      "    [0.9027] \"In other pattern recognition problems, the training data consists of a set of input\n",
      " ...\"\n",
      "    [0.8923] \"Applications in which the training data comprises examples of the input vectors\n",
      "alon ...\"\n",
      "    [0.8923] \"Applications in which the training data comprises examples of the input vectors\n",
      "alon ...\"\n",
      "\n",
      "QUESTION: \"explain what is pca\"\n",
      "ANSWER: \"PCA, or Principal Component Analysis, is a statistical technique used in machine learning to reduce the dimensionality of a dataset. This is done by finding the most important features or components of the data, and representing the data in a lower-dimensional space. This helps to simplify the data and make it easier for machine learning algorithms to process and analyze.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.8423] \"straightforward, and a clear understanding of them is essential if machine learning\n",
      " ...\"\n",
      "    [0.8423] \"straightforward, and a clear understanding of them is essential if machine learning\n",
      " ...\"\n",
      "    [0.8406] \"goals of this chapter is to introduce, in a relatively informal way, several of the  ...\"\n",
      "    [0.8405] \"goals of this chapter is to introduce, in a relatively informal way, several of the  ...\"\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
